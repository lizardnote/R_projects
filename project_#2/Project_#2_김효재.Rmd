---
title: 'assignment #2'
author: "20182477 김효재"
date: '2021 3 30 '
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
=================================================================================================
##1번 
1.1) ID와 ZIP.code를 feature에서 제외하기 
1.2) z-score normalization 활용한 정규화하기 
1.3) 첫 4000명의 데이터를 training set으로, 나머지 1000명의 데이터를 test set으로 사용하여 Training set과 test set에서의 PersonalLoan 값의 분포를 비교하기

```{r graph 1}

#먼저 사용할 패키지를 불러온다.
library(class)
library(ggplot2)
library(caret)

#bank변수에 CommonBank.csv 데이터 파일을 불러오고, 데이터 구조를 확인한다.
bank <- read.csv("C:/Users/chk/Documents/CommonBank.csv")
str(bank)

# 1-1) ID 와 ZIP codes를 feature에서 제외시킨 후 확인한다.
bank <- bank[,c(-1,-5)]
str(bank)

#target변수를 table 형태로 확인한다.
table(bank$PersonalLoan)

#0/1 (reject/accept) 수치형으로 표현된 target변수(PersonalLoan)를 factor로 변환하고, 알기 쉽게 label을 변경해준다.
#가입할지 예측을 하는 것이 목적이므로 accept(가입)가 더 중요하다고 판단해 카테고리를 앞쪽에 두었다.
bank$PersonalLoan <- factor(bank$PersonalLoan, levels=c(1,0), labels=c("가입_accept" , "미가입_reject"))
str(bank)

#table 형태로 확인해본다.
table(bank$PersonalLoan)

# 1-2) 정규화를 해준다.
# 정규화 방법으로는 MIN-MAX방법(최소최대정규화)과 z-score방법(z점수 표준화)이 있는데, 문제에서 제시한 z-score 방법을 사용했다.
#z-score normalization 1 : normalize 변수에 정규화 공식(x-평균/표준편차)을 저장해 정규화를 시켜준다.
normalize <- function(x){
  return((x-mean(x))/sd(x))
}

normalize(c(1,2,3,4,5))

bank_norm <- as.data.frame(lapply(bank[-8],normalize))
str(bank_norm)

#z-score normalization 2 : scale함수를 사용할 수도 있다.
bank_n <- as.data.frame(scale(bank[-8]))
str(bank_n)

#1,2 모두 summary함수를 통해 변환이 적용되었는지 확인한다.
summary(bank_norm$Age)
summary(bank_n$Education)

#TrainSet과 TestSet을 생성한다. 
bank_train <- bank_norm[1:4000,]
bank_test <- bank_norm[4001:5000,]

#target변수인 PersonalLoan은 초기 bank 데이터에서 label에 따로 저장한다.
bank_train_labels <- bank[1:4000,8]
bank_test_labels <- bank[4001:5000,8]

#TrainSet과 TestSet에서의 target변수 분포를 비교하기 위해 barplot을 그려보자
a <- table(bank_train_labels)
b <- table(bank_test_labels)
m <- matrix(c(a,b))
barplot(m, names=c("train_가입","train_미가입","test_가입","test_미가입"), beside = T, col = c(10,5))

#비율로 보기 쉽게 ggplot의 누적막대그래프로 그려보자
#trainset이 accept비율이 미세하게 많으나 거의 동일한 것을 확인할 수 있다.
df1 <- data.frame( Set = c("trainSet","trainSet","testSet","testSet"), result=c("accept","reject","accept", "reject"), num = c(397,3603, 83, 917))
df1

ggplot(df1,aes(x=Set, y=num, fill=result))+geom_bar(stat="identity", position = "fill")

#수치로 확인을 해보면 
397/4000 #trainset 
83/1000  #testset  
#거의 비슷하다.

```

===============================================================================================================
##2번 
5-NN을 적용하고 결과를 분석해보자

```{r graph 2}

#5-nn 적용
bank_test_pred <- knn(train=bank_train, test=bank_test, cl=bank_train_labels, k=5)
confusionMatrix(bank_test_pred, bank_test_labels)

```

#분석 결과 : bank_test_pred모델로 bank_test를 돌려보면 Accuracy : True를 True로, False를 False로 옳게 예측한 경우를 고려한 지표로 (TP+TN = 49+913)/(전체=1000) =  0.962 즉 96.2%인 것을 확인할 수 있다. 
#Sensitivity는 실제 True값 중에 True를 예측한 비율로(TP=49)(TP+FN=49+34)=0.5904로 약 59%이다. 즉 실제 가입자중에서 가입자임을 맞춘 정도는 정확도와 비교했을때 많이 떨어진다.
#이 문제에서 중요한 것은 새로운 고객을 대상으로 가입할지를 예측해야하기 때문에 Sensitivity가 높아야한다.



================================================================================================================

##3번 
Training set 중 마지막 800명의 데이터를 validation set으로 사용하여 다양한 k에 대해 k-NN을 적용하고, 예측 성능을 비교해라. k가 어떤 값을 가질때 모델의 성능이 가장 우수한가?

``` {r graph 3}

#trainset과 validationset 으로 나눠준다.
bank_train2 <- bank_norm[1:3200,]
bank_val <- bank_norm[3201:4000,]

#target인 PersonalLoan을 label에 따로 저장한다.
bank_train_labels2 <- bank[1:3200,8]
bank_val_labels <- bank[3201:4000,8]

str(bank_train2)
str(bank_val)

#K를 바꿔보면서 예측모델을 살펴본다.
pred2_k1 <- knn(train=bank_train2, test=bank_val, cl=bank_train_labels2, k=1)
pred2_k5 <- knn(train=bank_train2, test=bank_val, cl=bank_train_labels2, k=5)
pred2_k9 <- knn(train=bank_train2, test=bank_val, cl=bank_train_labels2, k=9)
pred2_k11 <- knn(train=bank_train2, test=bank_val, cl=bank_train_labels2, k=11)
pred2_k21 <- knn(train=bank_train2, test=bank_val, cl=bank_train_labels2, k=21)
pred2_k30 <- knn(train=bank_train2, test=bank_val, cl=bank_train_labels2, k=30)

confusionMatrix(pred2_k1, bank_val_labels)  #0.9575 #0.6389
confusionMatrix(pred2_k5, bank_val_labels)  #0.9525 #0.5000
confusionMatrix(pred2_k9, bank_val_labels)  #0.9462 #0.44444 
confusionMatrix(pred2_k11, bank_val_labels) #0.9388 #0.37500         
confusionMatrix(pred2_k21, bank_val_labels) #0.9362 #0.33333
confusionMatrix(pred2_k30, bank_val_labels) #0.93   #0.29167


#더 많은 k 값을 k-nn에 적용해보고 어떤 분포를 이루는지 확인해보자=============================================
# 여러개의 k에 대한 accuracy 값과 sensitivity 값을 저장할 변수를 선언한다.

sens_k <- vector()
accur_k <- NULL

#k값은 1부터 99까지 2간격으로 for문을 이용해 k-nn에 적용한다. 앞서 만들었던 벡터 sens_k에는 sensitivity값을, accur_k에는 accurity 값을 저장하자.
for (kk in seq(1,99,2)){
  set.seed(1234)
  knn_k <- knn(train=bank_train2,test=bank_val,cl=bank_train_labels2,k=kk)
  sens_k[kk] <- sum((bank_val_labels=="가입_accept")&(knn_k == "가입_accept"))/sum(bank_val_labels=="가입_accept") 
  accur_k <- c(accur_k, sum(knn_k == bank_val_labels)/length(bank_val_labels))
}

#for문이 잘 작동하여 저장되었는지 확인한다.
sens_k
accur_k

#na.omit함수를 이용하여 NA값을 제거하고, 가장 높은 accuracy값과 Sensitivity값을 확인한다.
sensitivity <- na.omit(sens_k)
accuracy  <- na.omit(accur_k)

max(accuracy)
max(sensitivity)

#data.frame에 valid_k와 valid_k2로 저장하고, plot함수를 이용해 나타냈다.
valid_k <- data.frame( k = seq(1,99,2), accuracy=accuracy)
valid_k2 <- data.frame( k = seq(1,99,2), sensitivity=sensitivity)

#accuracy
plot(valid_k,type="o",col = "purple",pch=20, main="accuracy")
with(valid_k, text(accuracy ~ k, labels = rownames(valid_k), pos = 1, cex = 0.7))

#sensitivity
plot(valid_k2,type="o",col = "hotpink",pch=20, main="sensitivity")
with(valid_k2, text(sensitivity ~ k, labels = rownames(valid_k2), pos = 1, cex = 0.7))

#accuracy & sensitivity
plot(valid_k, type = 'o', col = 'purple', pch=20, ylim = c(0,1), ylab="sensitivity & accuracy", xlab= "K", main="Performance")  # 첫 번째 그려진 그래프의 눈금으로 틀이 고정됩니다.
lines(valid_k2, type = 'o', col = 'hotpink', pch=20)
legend("right",c("accuracy", "sensitivity"), col = c("purple","hotpink"), pch = c(20,20))

# K=1일 때 가장 성능이 우수하다.
```
k=1일때 Accuracy가 0.9575 즉 95.75%로 가장 높다. 그리고 이때 모델의 Sensitivity는 0.6389인 63.89%이다. accuracy 그래프나 sensitivity 그래프 모두 k가 커질수록 감소하는 모습이 보인다. 마지막 그래프를 보면 k가 커질수록 accuracy와 비교했을때 sensitivity 값이 급격이 감소하는데 이러한 Sensitivity 때문에 전반적인 모델 성능이 낮아진다.

==================================================================================================================

##4번
training set에 대해 5-fold cross validation을 5회 반복하여 best k 값을 찾아보자. best k 값으로 만들어지는 최종 model에 test set을 적용하여 model의 성능을 report하자.

```{r graph 4}

bank_train3 <- bank[1:4000,]
bank_test3 <- bank[4001:5000,]

#train 함수에 들어갈 파라미터 값들을 먼저 넣어준다. train함수를 사용하기 전에는 set.seed()를 이용해 고정시켜준다.
cv=trainControl(method="repeatedcv", number=5, repeats = 5)
tune_grid <- data.frame(k=seq(1,99,2))
z_norm <- c("center", "scale")
set.seed(777)

# 5-Fold Cross Validation을 5회 반복해 knn_fit 변수에 저장한다.
knn_fit <- train(data = bank_train3, PersonalLoan~., method="knn",  trControl = cv, preProcess= z_norm, tuneGrid = tune_grid)

# Best K는 3이다.
knn_fit


# plot을 그려 k 변화에 따른 accuracy를 확인한다.
plot(knn_fit, )

#Best K로 만들어지는 최종 model에 test set을 적용하고 성능을 report하자

test_pred <- predict(knn_fit, bank_test3[,-8])
confusionMatrix(test_pred, bank_test3[,8], positive="가입_accept")

```
best k = 3으로 만든 최종 3-NN 모델에 test set을 적용했더니 정확도는 0.967 즉 96.7%로 높게 나왔다. 이때 sensitivity는 0.6506, specificity는 0.9956이 나왔다. 상대적으로 높은 accuracy와 sensitivity를 봤을 때 3-NN 모델은 상당히 유의하고 신뢰할 수 있는 모델이라고 볼 수 있다.


==============================================================================================================
##5. 3번과 4번에서 활용한 training방식의 장단점을 비교해보자

보편적인 모델의 성능 테스트 방법은 원 데이터를 훈련데이터와 테스트데이터 두개로 나누는 것이다.
하지만 이 방법은 모델을 만드는 과정에서 동일한 데이터셋으로 계속 재사용하게 되고, 훈련데이터의 의미가 사라지며 과적합되기 쉽다.

3번에서 사용한 방법은 Hold out validation(홀드아웃 메서드)으로 데이터를 세 부분으로 나누게 된다.
1. train data -> a. train b. validation 2. test data 즉 ((훈련데이터, 검증데이터), 테스트데이터) 세 개로 나뉜다.
여기서의 훈련 데이터는 말 그대로 훈련 데이터이고, 검증 데이터에 대한 성능을 높이는 작업을 학습에서 진행한다.
그리고 테스트 데이터를 이용하여 최종 성능을 추정하게 된다.

홀드아웃 교차검증의 큰 단점은 데이터셋 전체가 개수가 크지 않다면, 결과에 영향을 크게 미친다. 
또한 한개의 데이터 셋으로 모델의 성능을 평가하기 때문에 각 데이터셋이 전체 데이터를 통계적으로 대표하지 못할 가능성이 높다. 즉, 하나의 데이터셋에 다양한 특징을 지닌 데이터들이 포함되지 않을 수 있다는 것이다. 

이를 확인하는 방법으로는 새롭게 데이터를 셔플링하여 다시 모델을 학습시켰을 때 모델의 성능이 많이 차이가 난다면 이 문제라고 볼 수 있다.
 
4번에서 사용한 K-fold cross validation(교차 검증) 방벙은  K번만큼 검증 데이터셋과 훈련 데이터셋을 변경해가면서 거의 모든 데이터에 대해 검증을 하는 방법이다. 4번에서는 5 * 5 = 25개의 validation set에 대해 model 성능을 계산한 뒤, 이들의 평균으로 model을 평가하였다.

k-fold cv의 장점으로는 평가에 사용되는 데이터 편중을 막을 수 있고, overfitting이 되는 것을 방지할 수 있다. 
또한 모든 데이터 셋을 훈련에 활용할 수 있어 정확도를 향상시키고, 데이터 부족으로 인한 underfitting을 방지할 수 있다.
단점으로는 모델 훈련, 평가 시간이 오래 걸린다는 점이 있다.
 

 
 
 
 
 
 




