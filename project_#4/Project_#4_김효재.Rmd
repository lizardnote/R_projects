---
title: "Assignment#4"
author: "20182477 김효재"
date: '2021 5 3 '
output: 
  html_document: 
    highlight: tango
    theme: cosmo
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1.Predicting Delayed Flights

항공기의 연착(delay) 여부를 예측하는 것은 항공사와 공항 등 항공기 운항과
관련된 주체들에게 매우 중요하다. 항공기의 연착에 따라 대체 항공기
이용료, 숙박 비용, 공항 사용료 등의 비용 발생이 매우 크기 때문이다.
FlightRecords.csv 파일은 2004년 1월동안 Washington, DC 지역으로부터 New
York City로 운행한 2201개 의 항공기 운행 기록을 포함한다. 본 문제에서는
다음 7개의 변수를 사용하여 항공기의 연착 여부를 예측해 본다.

-   dayweek: 운행 요일 (1: Mon, 2: Tue, ..., 7: Sun)
-   deptime: 출발시각 (예: 1455 = 14시55분, 839: 8시39분)
-   origin: 출발공항코드(DCA: Reagan Nation, IAD: Dulles, BWI:
    Baltimore-Washington Int'l)-
-   dest: 도착공항코드(JFK: Kennedy, LGA: LaGuardia, EWR: Newark
-   carrier: 항공사코드(CO: Continental, DH: Atlantic Coast, DL: Delta,
    MQ: American Eagle,OH: Comair, RU: Continental Express, UA: United,
    US: USAirways)
-   weather: 날씨 (0: OK, 1: Bad)<br /> delay: 연착여부("delayed" or
    "ontime")<br />

### **1-1번**

다음의 순서로 data preprocessing을 진행하자.

-   수치값으로 표현되어 있는 출발시각을 6시부터 22시까지 각 시간대를
    나타내는 범주형 변수로 변환한다(Hint: 원 데이터를 100으로 나눈 후
    정수값으로 내림. 그 후 factor로 변환)

-   수치값으로 표현되어 있는 dayweek와 weather 변수를 factor로 변환한다.

-   factor로 표현되어 있는 delay 변수가 가지는 level의 순서를 "ontime",
    "delayed" 순으로 변환한다 (logistic regression 수행 시에 연착하는
    경우를 로 만들기 위해서).

```{r}

#필요한 패키지를 불러온다.

library(ggplot2)
library(dplyr)


#FlightRecords data를 불러온다.
data1_1 <- read.csv("C:/Users/chk/Documents/FlightRecords.csv")
str(data1_1)

#deptime이 6시 이전이거나 22시 이후인 데이터는 제외한다.
data1_1 <- subset(data1_1,deptime >= 600)
data1_1 <- subset(data1_1, deptime < 2200)
str(data1_1) 

#수치값으로 표현되어 있는 deptime을 6~22시까지 각 시간대를 나타내는 볌주형 변수로 변환한다.
#원데이터(deptime)를 100으로 나눈 후 floor 함수를 이용해 내림해준다.
#그 후 factor형으로 전환한다.

data1_1$deptime <- floor(data1_1$deptime/100)
data1_1$deptime <- factor(data1_1$deptime)
str(data1_1)

#수치값으로 표현된 dayweek와 weather변수를 factor로 변환한다.
data1_1$dayweek <- factor(data1_1$dayweek)
data1_1$weather <- factor(data1_1$weather)
str(data1_1)

#factor로 표현되어 있는 delay 변수가 가지는 level의 순서를 “ontime”, “delayed” 순으로 변환한 뒤 확인한다.
data1_1$delay <- factor(data1_1$delay, levels=c("ontime","delayed"))
levels(data1_1$delay)

```

### 1-2번

요일 별 연착비율, 출발 시간대 별 연착 비율, 출발 공항 별 연착비율, 도착
공항 별 연착 비율, 항공사 별 연착비율, 날씨 별 연착 비율을 각각 그래프로
시각화해보자. 어떤 특성을 관찰할 수 있는가?

```{r}
#요일 별 연착비율 그래프
#dayweek : 운행요일(1~7:MON~SUN) 과 delay 이용

ggplot(data1_1, aes(x=dayweek, fill=delay)) + geom_bar(position=position_dodge(preserve="single")) + scale_x_discrete(labels=c("Mon","Tue","Wed","Thu","Fri","Sat","Sun")) + labs(title="요일 별 연착비율", subtitle="2019-11-04 ~ 2019-11-10", x="요일", y="연착건수", fill="연착여부") 

#더 알아보기 쉽게 비율을 계산해 그래프로 시각화하자
ggplot(data1_1, aes(x=dayweek, fill=delay)) + geom_bar(position="fill") + scale_x_discrete(labels=c("Mon","Tue","Wed","Thu","Fri","Sat","Sun")) + labs(title="요일 별 연착비율", subtitle="2019-11-04 ~ 2019-11-10", x="요일", y="연착율", fill="연착여부")+ geom_text(data = . %>%  group_by(dayweek, delay) %>% tally() %>%  mutate(p = n / sum(n)) %>% ungroup(),aes(y = p, label = scales::percent(p,accuracy = 2)),position = position_stack(vjust = 0.5), show.legend = FALSE)

```

<br/>

-   **요일 별 연착율**은 월요일과 일요일이 약 26%로 가장 높고 토요일의
    연착율이 약 8%로 가장 낮게 나타났다. 주중(화,수,목,금)의 연착율은 큰
    차이가 없으나 조금 감소하다가 다시 높아지는 모습을 보인다.

<br/>

```{r}

#출발 시간대 별 연착비율 그래프
#deptime 과 delay 이용

ggplot(data1_1, aes(x=deptime, fill=delay)) + geom_bar(position=position_dodge(preserve="single")) + scale_x_discrete(labels=paste0(c(6:21),"시")) + labs(title="시간대 별 연착비율", x="시간대", y="연착건수", fill="연착여부") 

ggplot(data1_1, aes(x=deptime, fill=delay)) + geom_bar(position="fill") + scale_x_discrete(labels=paste0(c(6:21),"시")) + labs(title="시간대 별 연착비율", x="시간대", y="연착율", fill="연착여부")+geom_text(data = . %>%  group_by(deptime, delay) %>% tally() %>%  mutate(p = n / sum(n)) %>% ungroup(),aes(y = p, label = scales::percent(p,accuracy = 2)),position = position_stack(vjust = 0.5), show.legend = FALSE)


```

<br/>

-   **시간대별 연착 비율**에서 가장 높은 연착율을 보이는 것은 **19시 약
    52%**, 그 다음은 15시 약 34%로 나타났으며 가장 낮은 연착율을 보이는
    시간대는 12시 약 6%로 나타났다. 대체적으로 오후 시간대가 20% 근처의
    연착율을 보인다.

<br/>

```{r}
#출발 공항 별 연착비율 그래프
#origin 과 delay 이용

ggplot(data1_1, aes(x=origin, fill=delay)) + geom_bar(position=position_dodge(preserve="single")) + scale_x_discrete(labels=c("DCA","IAD","BWI")) + labs(title="출발 공항 별 연착비율", x="공항", y="연착건수", fill="연착여부")

ggplot(data1_1, aes(x=origin, fill=delay)) + geom_bar(position="fill") + scale_x_discrete(labels=c("DCA","IAD","BWI")) + labs(title="출발 공항 별 연착비율", x="공항", y="연착율", fill="연착여부")+geom_text(data = . %>%  group_by(origin, delay) %>% tally() %>%  mutate(p = n / sum(n)) %>% ungroup(),aes(y = p, label = scales::percent(p,accuracy = 2)),position = position_stack(vjust = 0.5), show.legend = FALSE)

#도착 공항 별 연착비율 그래프
#dest와 delay 이용

ggplot(data1_1, aes(x=dest, fill=delay)) + geom_bar(position=position_dodge(preserve="single")) + scale_x_discrete(labels=c("JFK","LGA","EWR")) + labs(title="도착 공항 별 연착비율", x="공항", y="연착건수", fill="연착여부")

ggplot(data1_1, aes(x=dest, fill=delay)) + geom_bar(position="fill") + scale_x_discrete(labels=c("JFK","LGA","EWR")) + labs(title="도착 공항 별 연착비율", x="공항", y="연착율", fill="연착여부")+geom_text(data = . %>%  group_by(dest, delay) %>% tally() %>%  mutate(p = n / sum(n)) %>% ungroup(),aes(y = p, label = scales::percent(p,accuracy = 2)),position = position_stack(vjust = 0.5), show.legend = FALSE)

```

<br/>

-   **출발/도착 공항 별 연착비율** -

-   출발 공항 별 연착율은 DCA(:Reagan Nation) \>
    BWI(:Baltimore-Washington Int) \> IAD(:Dulles) 순으로 높으며 도착
    공항 별 연착율은 JFK(:Kennedy) \> LGA(: LaGuardia) \> EWR(:Newark)
    순으로 높다.

<br/>

```{r}
#항공사 별 연착비율 그래프
#carrier와 delay 이용

ggplot(data1_1, aes(x=carrier, fill=delay)) + geom_bar(position=position_dodge(preserve="single")) + scale_x_discrete(labels=c("CO","DH","DL","MQ","OH","RU","UA","US")) + labs(title="항공사 별 연착비율", x="항공사", y="연착건수", fill="연착여부")

ggplot(data1_1, aes(x=carrier, fill=delay)) + geom_bar(position="fill") + labs(title="항공사 별 연착비율", x="항공사", y="연착율", fill="연착여부")+geom_text(data = . %>%  group_by(carrier, delay) %>% tally() %>%  mutate(p = n / sum(n)) %>% ungroup(),aes(y = p, label = scales::percent(p,accuracy = 2)),position = position_stack(vjust = 0.5), show.legend = FALSE)

```

<br/>

-   **항공사 별 연착비율** : 항공사 MQ(:American Eagle)와
    CO(:Continental)가 약 28%로 가장 높은 연착율을 보여준다. 그
    다음으로는 DH(:Atlantic Coast), RU(:Continental Express) 약 22%, 그
    다음으로는 UA(:United) \> OH(:Comair) \> DL(:Delta) 순으로 높으며
    가장 낮은 연착율 약 8%를 보이는 항공사는 US(:USAirways)이다.

<br/>

```{r}
#날씨 별 연착비율 그래프
#weather과 delay 이용

ggplot(data1_1, aes(x=weather, fill=delay)) + geom_bar(position=position_dodge(preserve="single")) + scale_x_discrete(labels=c("OK","BAD")) + labs(title="날씨 별 연착비율", x="날씨", y="연착건수", fill="연착여부")

ggplot(data1_1, aes(x=weather, fill=delay)) + geom_bar(position="fill") + scale_x_discrete(labels=c("OK","BAD")) + labs(title="날씨 별 연착비율", x="날씨", y="연착율", fill="연착여부")+geom_text(data = . %>%  group_by(weather, delay) %>% tally() %>%  mutate(p = n / sum(n)) %>% ungroup(),aes(y = p, label = scales::percent(p,accuracy = 2)),position = position_stack(vjust = 0.5), show.legend = FALSE)


```

-   **날씨별 연착비율** - 날씨가 좋은 날의 경우 약 18% 정도의 낮은
    연착율을 보이나 **BAD인 경우는 100% 연착율**을 보이고 있다.

<br/>

### 1-3번

7개의 모든 변수들 간의 상관관계를 시각화해보자. 어떤 특성을 관찰할 수
있는가?

```{r}
library(psych)
library(corrplot)

#7개의 변수들만 data1_1 data frame에서 선택하여 상관관계를 확인한다.
data1_3 <- data1_1[c(2,3,4,8,9,10,13)]
str(data1_3)
pairs.panels(data1_3, main = "7개 변수들의 상관관계")

```

<br/>

-   먼저 Target 변수(=delay)와 다른 feature 간의 관계를 살펴보자.
    **\<weather, origin, deptime\> 변수는 delay와 양의 상간관계**를
    보이고, **\<dayweek, dest, carrier\> 변수는 음의 상관관계**를
    보인다. 그리고 전체적으로 봤을때, 7개 변수들 사이에 강한 양의
    상관관계는 보이지 않는다. 따라서 다중공산성을 의심할 필요는 없을 것
    같다.

<br/>

### 1-4번

데이터셋을 70:30 비율로 training set과 test set으로 분할하자. 이때
stratified sampling을 활용하여 두 set에서 delay 변수의 분포가 크게
차이가 없도록 분할하자.

```{r}
#동등배분-> 훈련데이터와 테스트데이터에 특정 컬럼값(delay)을 기준으로 동등한 비율로 랜덤배분을 해준다.
# 1) caret 패키지의 createDataPartition() 
# 2) rsample 패키지의 initial_split()
# 3) caTools 패키지의 sample.split()가 있는데 
#이미 설치된 caret패키지와 rsample과 함수(1,2번) 방법을 사용해 동일하게 나오는지 확인해보자.

library(caret)
library(rsample)

#createDataPartition 사용
set.seed(777)
idx = createDataPartition(data1_3$delay, list=F, p=0.7)
Train <- data1_3[ idx,]
Test <- data1_3[-idx,]

#initial_split 사용
set.seed(777)
split <- initial_split(data1_3, prop =0.7, strata = "delay")
train<- training(split)
test <- testing(split)


#둘 다 동일하게 동등하게 배분된 것을 확인할 수 있다.

table(Train$delay)
table(Test$delay)

table(train$delay)
table(test$delay)


#나눠진 데이터를 시각화하여 확인해보자
ggplot(Train, aes(x=delay)) + geom_density(color="darkred")+ geom_density(data=Test ,aes(x=delay), color="blue")

df <- data.frame(Set = c("trainSet","trainSet","testSet","testSet"), result=c("ontime","delayed","ontime","delayed"), num = c(1225,287,525,122))
df

ggplot(df,aes(x=Set, y=num, fill=result))+geom_bar(stat="identity", position = "fill")

```

<br/>

-   그래프를 보면 두 set에서 delay 변수의 분포가 거의 동등하게 배분된
    것을 확인할 수 있다.

<br/>

### 1-5번

데이터 시각화로부터 weather 변수가 "Bad" 인 경우에는 항상 항공기가
연착되는 것을 관찰할 수 있다. 따라서 weather가 Bad이면 항공기가
연착되고, weather가 OK일 경우 항공기가 연착되지 않는 것으로 예측하는
단순한 모델을 baseline model이라 하자. Test set에 대해 baseline model을
적용했을 때 confusion matrix를 계산해 보세요.

```{r}

library(caret)

#먼저 baseline model을 만들어준다.
# weather: 날씨 (0: OK, 1: Bad)
pred_base <- factor(sign(Test$weather == 1), levels = c(0, 1), labels = c("ontime", "delayed"))

#그 다음 confusion matrix를 계산하자
confusionMatrix(pred_base, Test$delay, positive = "delayed")

```

<br/>

| baseline model | 값      |
|:---------------|:--------|
| Accuracy       | 0.8253  |
| Sensitivity    | 0.07377 |
| Specificity    | 1.00000 |

으로 꽤 높은 정확도를 보인다. <br/>

이 baseline model은 Bad -\> delayed // OK -\> ontime 으로 예측한다.
<br/>

실제 delayed를 ontime으로 예측(FP) : **113건** (꽤 많은 건수를 잘못
예측했다.) 실제 ontime을 delayed로 예측(FN): **0건** delayed를 중요하게
예측해야 할 때는 사용하기 좋지 못한 모델이다.

### 1-6번

Training set을 대상으로, 연착여부(delay)를 나머지 모든 변수를 사용하여
예측하기 위한 logistic regression model을 수립해보자.

<br/>

-   1\. 변수 deptime19의 regression coefficient에 대한 추정값은
    얼마인가? 이 추정값을 바탕으로 출발시각이 19시대인 항공기에 대해서
    어떠한 해석을 할 수 있는가? (Hint: 범주형 변수 deptime을 model에
    추가할 때 deptime6을 제외한 deptime7 \~ deptime21에 대한 dummy
    변수가 만들어진다.)

-   2\. 날씨에 문제가 없는 금요일 15시에 IAD에서 출발하여 JFK로 도착한
    Delta 항공기가 연착될 확률은 얼마로 예측되는가?

-   3\. Threshold 에 대해서 각각 test set에 대한 confusion matrix를
    계산해 보자. 어떠한 경향을 관찰할 수 있는가?

-   4\. Baseline model과 logistic regression model의 성능을 비교해보자.
    <br/>

#### 6-1번

```{r}
#6_1.변수 deptime19의 regression coefficient에 대한 추정값은 얼마인가?  출발시각이 19시대인 항공기에 대해서 어떠한 해석을 할 수 있는가?

#logistic regression을 위해서는 glm()함수에 family="binomial"를 지정해야 한다.
model_log <- glm(delay~., family="binomial", data= Train)
summary(model_log)

#어떤 변수의 영향력이 가장 큰지 확인할 수 있다.
library(vip)
vip(model_log)

```

<br/>

-   deptime19의 regression coefficient에 대한 추정값 : **2.27768**

-   다른 변수에 비해 큰 추정값과, 그래프를 봤을 때 delay에 영향을 많이
    주는 것으로 해석된다. 1-2번에서 그린 그래프에서도 19시 연착비율이
    가장 높았다.

<br/>

#### 6-2

```{r}

#6_2 날씨에 문제가 없는 금요일 15시에 IAD에서 출발하여 JFK로 도착한 Delta 항공기가 연착될 확률은 얼마로 예측되는가?

#조건에 맞는 dataframe을 생성한뒤 predict 함수를 사용해 예측하자.
df6_2 <- data.frame(dayweek="5", deptime="15", origin ="IAD", dest="JFK", carrier = "DL", weather="0")
df6_2

test_df_prob <- predict(model_log, newdata=df6_2, type="response")
test_df_prob


```

<br/>

-   문제 조건을 위에서 생성한 model에 적용했을 때 연착할 확률 :
    **0.2431289**

<br/>

#### 6-3

```{r}
#6_3. Threshold 에 대해서 각각 test set에 대한 confusion matrix를 계산해 보자. 어떠한 경향을 관찰할 수 있는가?

#test set에 포함된 지연 여부 확률을 계산한다. 
#type 은 0~1 사이 확률인 response를 사용

test_prob6 <-predict(model_log, newdata=Test, type="response")

#0.2
nrow(Test)
test_pred0.2 <- rep("ontime",647)
test_pred0.2[test_prob6 > 0.2] <- "delayed"
confusionMatrix(factor(test_pred0.2), Test$delay, positive = "delayed")

#0.3
test_pred0.3 <- rep("ontime",647)
test_pred0.3[test_prob6 > 0.3] <- "delayed"
confusionMatrix(factor(test_pred0.3), Test$delay, positive = "delayed")

#0.5
test_pred0.5 <- rep("ontime",647)
test_pred0.5[test_prob6 > 0.5] <- "delayed"
confusionMatrix(factor(test_pred0.5), Test$delay, positive = "delayed")

#0.7
test_pred0.7 <- rep("ontime",647)
test_pred0.7[test_prob6 > 0.7] <- "delayed"
confusionMatrix(factor(test_pred0.7), Test$delay, positive = "delayed")


```

<br/>

| Threshold   | k =0.2 |         | k =0.3  |         | k =0.5  |         | k =0.7  |         |
|:------------|:-------|:--------|:--------|:--------|:--------|:--------|:--------|:--------|
| Prediction  | ontime | delayed | ontime  | delayed | ontime  | delayed | ontime  | delayed |
| ontime      | 376    | 47      | 461     | 70      | 518     | 95      | 524     | 109     |
| delayed     | 149    | 75      | 64      | 52      | 7       | 27      | 1       | 13      |
|             |        |         |         |         |         |         |         |         |
| Accuracy    | 0.6971 |         | 0.7929  |         | 0.8423  |         | 0.83    |         |
| Kappa       | 0.2505 |         | 0.3102  |         | 0.2876  |         | 0.1585  |         |
| Sensitivity | 0.6148 |         | 0.42623 |         | 0.22131 |         | 0.10656 |         |
| Specificity | 0.7162 |         | 0.87810 |         | 0.98667 |         | 0.99810 |         |

<br/>

-   4개의 Threshold (0.2, 0.3, 0.5, 0.7)로 만든 confusion matrix, 그리고
    각각의 accuracy, kappa, sensitivity, specificity를 테이블로
    나타냈다. k값이 커지면서 점점 Accuracy가 증가하지만 0.5에서 가장
    커진 뒤, 0.7에서 0.5보다 감소한 것을 확인할 수 있다. Threshold가
    증가할수록 sensitivity는 점점 감소하고, specificity는 증가하는
    모습을 보인다.

#### 6-4번

Baseline model과 logistic regression model의 성능을 비교해보자.

| model       | Baseline | logistic regression                  |
|-------------|----------|--------------------------------------|
| Accuracy    | 0.8253   | 0.6971 / 0.7929 / **0.8423** / 0.83  |
| Sensitivity | 0.07377  | 0.6148 / 0.42623 / 0.22131 / 0.10656 |
| Specificity | 1.00000  | 0.7162 / 0.87810 / 0.98667/ 0.99810  |

-   단순한 baseline model은 logistic regression model에 비교했을 때 엄청
    큰 차이가 있지는 않지만 Threshold 0.5, 0.7 기준 accuracy가 더 낮다는
    것을 확인할 수 있다. (하지만 Threshold 0.2, 0.3일 때보다는 baseline
    model의 성능이 더 좋다.)

-   이 중에서 가장 좋은 성능을 가진 모델은 **K= 0.5 threshold의 logisitc
    regression model**이다.

### 1-7번

training set을 대상으로, step() 함수를 활용한 backward stepwise
selection을 적용하여 logistic regression model을 수립해보자.

-   모델에 몇 개의 변수가 포함되었는가?
-   Threshold 0.5 일때 test set에 대한 confusion matrix를 계산해 보자.

```{r}

#step함수를 이용해 stepwise logistic regression
model_step <- step(model_log, direction="backward")

#coef 함수를 사용해 포함된 변수를 살펴보자
coef(model_step)



#앞에서 얻은 모델을 사용해 test set 예측 수행
test_prob7 <- predict(model_step, newdata=Test, type="response")
nrow(Test)
test_pred7 <- rep("ontime", 647)
test_pred7[test_prob7 > 0.5] <- "delayed"
confusionMatrix(factor(test_pred7), Test$delay, positive="delayed")

```

<br/>

-   이 모델에는 carrierDH, carrierDL, carrierMQ, carrierOH, carrierRU,
    carrierUA, carrierUS, deptime7, deptime8, deptime9, deptime10,
    deptime11, deptime12, deptime13, deptime14, deptime15, deptime16,
    deptime17, deptime18, deptime19, deptime20, deptime21, destJFK,
    destLGA, originDCA, originIAD, weather1, dayweek2, dayweek3,
    dayweek4, dayweek5, dayweek6, dayweek7 **총 33개의 변수가
    포함된다.**

-   **이 모델(k=0.5) test set Accuracy는 0.8423, Sensitivity는 0.22131,
    Specificity는 0.98667이다.**

| Prediction | ontime | delayed |
|:-----------|:-------|:--------|
| ontime     | 518    | 95      |
| delayed    | 7      | 27      |

confusion matrix를 보면 각각 T-\> T, F-\> F로 분류한 것은 518, 27이고
F-\> T로, T-\>F로 분류한 것은 95, 7이다. 이 모델은 실제 delayed를
ontime으로 잘못 예측한 False Positive가 FN보다 더 높게 나타났다.

### 1-8번

Training set을 대상으로 Lasso regression을 적용하여 logistic regression
model을 수립해보자.

<br/>

-   \_\_1. 모델에 어떠한 변수들이 포함되었는가?
-   \_\_2. Threshold 0.5 일때 test set에 대한 confusion matrix를 계산해
    보자.

<br/>

```{r}

library(glmnet)

#delay변수가 몇번째인지 확인
str(Train)

#feature matrix를 생성한다.
Xtrain <- model.matrix(delay~. ,data = Train)[,-7]
Ytrain <- Train$delay

#glmnet 함수의 family="binominal"옵션을 추가해 lasso regularization을 적용할 수 있다.
set.seed(8)
lasso <- glmnet(x= Xtrain, y= Ytrain, alpha=1, family="binomial")
plot(lasso, xvar="lambda")
print(lasso)

#type.measure="auc"로 설정하면 AUC값을 기준으로 cv를 수행한다.(="class"인 경우 accuracy 기준 cv 수행)
set.seed(9)
cv_lasso <- cv.glmnet(x= Xtrain, y= Ytrain, alpha=1, type.measure = "auc", family="binomial", nfolds=10)
plot(cv_lasso)


#점선으로 표시된 부분의 값을 확인하자.
log(cv_lasso$lambda.min) 
log(cv_lasso$lambda.1se)

#performance measure출력
cv_lasso$cvm
#cv에 사용된 lambda와 최소값 출력
cv_lasso$lambda
cv_lasso$lambda.min
cv_lasso$lambda.1se

#nonzero 변수의 수 출력
cv_lasso$nzero

#lambda.1se 이용 -변수 개수가 11개일 때
lambda_1se <- cv_lasso$lambda.1se
coef(cv_lasso, s = lambda_1se)

#변수의 개수가 15개일 때
lambda <- cv_lasso$lambda[21]
coef(cv_lasso, s = lambda)

#test set에 대한 delayed 확률 예측
test_prob8 <- predict(cv_lasso, newx = model.matrix(delay~., data=Test)[,-7], s=lambda_1se, type="response")
test_prob8_1 <- predict(cv_lasso, newx = model.matrix(delay~., data=Test)[,-7], s=lambda, type="response")

test_prob8[1:20]
test_prob8_1[1:20]

#Threshold K= 0.5 일때 test set에 대한 confusion matrix를 계산해 보자.
test_pred8 <- rep("ontime", 647)
test_pred8[test_prob8 > 0.5] <- "delayed"
confusionMatrix(factor(test_pred8), Test$delay, positive="delayed")

test_pred8_1 <- rep("ontime", 647)
test_pred8_1[test_prob8_1 > 0.5] <- "delayed"
confusionMatrix(factor(test_pred8_1), Test$delay, positive="delayed")


```

-   변수가 11개일 때, 17개일 때 정확도가 0.8269 ,0.83 으로 큰 차이가
    없다고 생각해 변수가 11개 사용된 모델을 택했다. 이때 **사용된
    변수들은 carrierDL, carrierMQ, carrierUS, deptime8, deptime12,
    deptime15, deptime19, originDCA, weather1, dayweek6, dayweek7** 가
    있다.

<br/>

| Prediction | ontime | delayed |
|:-----------|:-------|:--------|
| ontime     | 525    | 112     |
| delayed    | 0      | 10      |

<br/>

-   이 모델의 threshold K가 0.5일 때 test set **Accuracy는 0.8269,
    Sensitivity : 0.08197, Specificity : 1** 이다. confusion matrix를
    보면 각각 T-\> T, F-\> F로 분류한 것은 525, 10이고 T-\>F로 F-\> T로
    분류한 것은 0,112 이다. 실제 ontime을 delayed로 예측한 것은 0이지만,
    실제 delayed를 ontime으로 예측한 것은 112로 False Positive는 높게
    나타났다.

<br/>

### 1-9번

6,7,8번에서 수립한 logisitic regression model 들에 대해서, test set에
대한 성능을 나타내는 ROC Curve를 하나의 그래프로 시각화 하고, AUC값을
비교해보자

<br/>

```{r}

library(ROCR)

#6번 -> test_prob6_2
predict1 <- prediction(test_prob6, Test$delay, c("ontime","delayed"))
prf1 <- performance(predict1, measure="tpr",x.measure="fpr")

#7번 -> test_prob7
predict2 <- prediction(test_prob7, Test$delay, c("ontime","delayed"))
prf2 <- performance(predict2, measure="tpr",x.measure="fpr")

#8번 -> test_prob8
predict3 <- prediction(test_prob8, Test$delay, c("ontime","delayed"))
prf3 <- performance(predict3, measure="tpr",x.measure="fpr")

#각각 그래프로 살펴보면
par(mfrow=c(1,3))
plot(prf1, col="hotpink",lwd=3, lty=1, main = "6 model의 ROC curve", ylab = "TPR(sensitivity)", xlab = "FPR(1-specificity)")
abline(a=0,b=1,col="black",lwd=1.7,lty=6)
plot(prf2, col="purple",lwd=3, lty=1, main = "7 model의 ROC curve", ylab = "TPR(sensitivity)", xlab = "FPR(1-specificity)")
abline(a=0,b=1,col="black",lwd=1.7,lty=6)
plot(prf3, col="red",lwd=3, lty=1, main = "8 model의 ROC curve", ylab = "TPR(sensitivity)", xlab = "FPR(1-specificity)")
abline(a=0,b=1,col="black",lwd=1.7,lty=6)

#AUC값 비교를 위해 각각의 AUC값
auc1 <- performance(predict1, measure = "auc")
auc1<- auc1@y.values
auc2 <- performance(predict2, measure = "auc")
auc2 <- auc2@y.values
auc3 <- performance(predict3, measure = "auc")
auc3 <- auc3@y.values

#그래프를 한번에 그려서 확인해보자
par(mfrow=c(1,1))
plot(prf1, col="pink",lwd=12, lty=1, main = "6,7,8번 model의 ROC curve", ylab = "TPR(sensitivity)", xlab = "FPR(1-specificity)")
plot(prf2, col="purple",lwd=3,lty=6, add=TRUE)
plot(prf3, col="red",lwd=3, add=TRUE)
abline(a=0,b=1,col="black",lwd=2,lty=6)
abline(0,1)
legend('bottomright', inset=.1, legend=c("model_6  AUC: 0.7295863", "model_7  AUC: 0.7295863" , "model_8  AUC: 0.7262998"), col=c('pink', 'purple', 'red'), lty=1, lwd=2) 

```

<br/>

세개의 그래프가 거의 비슷하게 겹쳐있는 것으로 보아 성능 차이가 크지
않음을 확인할 수 있다. 각각의 **AUC값은 model6(분홍): 0.7295863,
model7(보라) : 0.7295863, model8(빨강): 0.7262998** 이다.

<br/>

### 1-10번

Training Set을 대상으로 k-nn을 적용해보자. 이때 train함수를 사용한 cross
validation으로 Accuracy가 가장 높은 best K값을 찾는다.

-   best 값은 얼마인가?

-   Test set에 대한 confusion matrix를 계산해 보자. 그리고 Test set에
    대한 성능을 앞서 수립한 logistic regression model들과 비교해보자

```{r}

#5 fold cross validation을 5회 적용한다.
cv <- trainControl(method = "repeatedcv", number = 5, repeats = 5)
#K 값에 대한 parameter tuning 수행한다.
tune_grid <- expand.grid(k = seq(1, 99, 2))


#method(학습모델) = "knn"으로 지정하고 train방법으로는 cv를 지정해준다.
set.seed(777)
knn_fit <- train(data = Train, delay ~., method = "knn", trControl = cv, tuneGrid = tune_grid)

knn_fit

#그래프를 그려 확인해보자
plot(knn_fit, type = 'o', col = 'purple', pch=20, main="Best K 확인")

#predict 함수를 이용하여 최종 model을 test set에 적용해 confusion matrix를 그려보자
Test_pred <- predict(knn_fit, Test[,-7])
confusionMatrix(Test_pred, Test$delay, positive = "delayed")

```

-   **best k = 7**임을 확인할 수 있다.

-   Test set에 대한 성능을 앞서 수립한 logistic regression model들과
    비교해보면 T-\>T로 F-\>F 예측은 521개, 8개 이며 실제 delayed를
    ontime이라고 예측한 것은 114개, 실제 ontime을 delayed로 예측한 것은
    4개이다.

-   위 모델의 성능은 Accuracy: 0.8176 Sensitivity: 0.06557 Specificity:
    0.99238 이다.

-   앞서 수립한 model들과 성능을 비교해보자

    | model      | Accuracy |
    |------------|----------|
    | 1-6 model  | 0.8423   |
    | 1-7 model  | 0.8423   |
    | 1-8 model  | 0.8269   |
    | 1-10 model | 0.8176   |

    가장 정확도가 높은 모델은 6,7번 모델이고 가장 정확도가 낮은 모델은
    10번에서 만든 knn 모델임을 확인할 수 있다.

## 2. OJ Dataset

-   ISLR 패키지에 속해 있는 OJ 데이터셋은 Citrus Hill과 Minute Maid
    Orange Juice를 구매한 1,070명의 고객에 대한 정보를 포함한다.

-   고객 및 제품 정보를 담고 있는 17개의 feature를 사용하여 고객이 두
    제품 중 어떤 것을 구 매할지(Purchase 변수) 예측하는 모델을 SVM을
    활용하여 만들어본다.

-   Linear, RBF, Polynomial Kernel을 사 용한 SVM 모델을 만들어보고
    성능을 비교해보자. 어떤 SVM 모델이 가장 좋은 성능을 보이는가?

```{r}
#ISLR 패키지를 사용한다.
library(ISLR)

#데이터를 불러오고 구조를 확인해보자
data(OJ)
str(OJ)

#분석에 앞서 NA값이 없는지 확인하고 CH와 MM의 개수를 확인해보자
sum(is.na(OJ))
table(OJ$Purchase)

#이번에는 createDataPartition()함수로 train set과 test set을 동등하게 배분해준다.
set.seed(123)
idxx = createDataPartition(OJ$Purchase, list=F, p=0.7)
OJ_Train <- OJ[ idxx,]
OJ_Test <- OJ[-idxx,]

#잘 배분되었는지 확인해보자
table(OJ_Train$Purchase)
table(OJ_Test$Purchase)

ggplot(data=OJ_Train, aes(x=Purchase)) + geom_density() + geom_density(data=OJ_Test, aes(x=Purchase), color="red")

OJ_df <- data.frame(Set = c("trainSet","trainSet","testSet","testSet"), result=c("CH","MM","CH","MM"), num = c(458,292,195,125))
OJ_df

ggplot(OJ_df,aes(x=Set, y=num, fill=result))+geom_bar(stat="identity", position = "fill")

#SVM을 수행할 수 있는 대표적인 e1071 패키지를 불러온다.
#SVM 수행 시 함수 자체에서 변수 scaling을 수행해주기 때문에 별도의 scaling을 진행하지 않아도 된다.

library(e1071)

#kernal에 따른 조정인자 튜닝을 진행한다.
#RBF svm에서는 gamma와 cost 값이, polynomial svm에서는 degree와 cost값이 필요하다.
set.seed(123)
tune.linear<- tune.svm(Purchase~., data=OJ_Train, cost=2^(0:4),kernal="linear")
tune.RBF <- tune.svm(Purchase~., data=OJ_Train, gamma=2^(-5:0), cost=2^(0:4), kernal="radial")
tune.poly <- tune.svm(Purchase~., data=OJ_Train, cost=2^(0:4),degree=2:4, kernal="polynomina")

#best parameter 값 출력
tune.linear$best.parameters
tune.RBF$best.parameters
tune.poly$best.parameters

#best parameter 값을 넣어서 svm 수행하기
linear_svm <- svm(Purchase~., data=OJ_Train, cost=1, kernel="linear")
RBF_svm <- svm(Purchase~., data=OJ_Train, gamma =0.03125, cost=2, kernel="radial")
poly_svm <- svm(Purchase~., data=OJ_Train, degree=2, cost=1, kernel="polynomia")

#결과 출력
summary(linear_svm)
summary(RBF_svm)
summary(poly_svm)

# best parameter 값을 넣어 svm 수행한 모델로 예측
linear_svm_predict <- predict(linear_svm, OJ_Test)
RBF_svm_predict <- predict(RBF_svm, OJ_Test)
poly_svm_predict <- predict(poly_svm, OJ_Test)

confusionMatrix(linear_svm_predict, OJ_Test$Purchase)
confusionMatrix(RBF_svm_predict, OJ_Test$Purchase)
confusionMatrix(poly_svm_predict, OJ_Test$Purchase)


```

| model      | accuracy | Sensitivity | Specificity | 실제 MM -\> CH | 실제 CH -\> MM |
|------------|----------|-------------|-------------|----------------|----------------|
| linear     | 0.8062   | 0.8256      | 0.7760      | 28             | 34             |
| RBF        | 0.8125   | 0.8615      | 0.7360      | 33             | 27             |
| polynomial | 0.7906   | 0.8872      | 0.6400      | 45             | 22             |

-   **가장 좋은 성능을 가진 svm모델은 RBF SVM 모델**이다. 세 모델 중
    FP가 가장 높은 모델은 polynomial 모델이고, FN이 가장 높은 모델은
    linear 모델이다.
